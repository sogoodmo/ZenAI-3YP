{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4759018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\moham\\desktop\\third year project\\mp_env\\lib\\site-packages (0.8.11)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\moham\\desktop\\third year project\\mp_env\\lib\\site-packages (4.6.0.66)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\moham\\desktop\\third year project\\mp_env\\lib\\site-packages (from mediapipe) (4.6.0.66)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\moham\\desktop\\third year project\\mp_env\\lib\\site-packages (from mediapipe) (3.6.2)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\moham\\desktop\\third year project\\mp_env\\lib\\site-packages (from mediapipe) (3.19.6)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\moham\\desktop\\third year project\\mp_env\\lib\\site-packages (from mediapipe) (22.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\moham\\desktop\\third year project\\mp_env\\lib\\site-packages (from mediapipe) (1.23.4)\n",
      "Requirement already satisfied: absl-py in c:\\users\\moham\\desktop\\third year project\\mp_env\\lib\\site-packages (from mediapipe) (1.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\moham\\desktop\\third year project\\mp_env\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\moham\\desktop\\third year project\\mp_env\\lib\\site-packages (from matplotlib->mediapipe) (1.0.6)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\moham\\desktop\\third year project\\mp_env\\lib\\site-packages (from matplotlib->mediapipe) (9.3.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\moham\\desktop\\third year project\\mp_env\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\moham\\desktop\\third year project\\mp_env\\lib\\site-packages (from matplotlib->mediapipe) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\moham\\desktop\\third year project\\mp_env\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\moham\\desktop\\third year project\\mp_env\\lib\\site-packages (from matplotlib->mediapipe) (4.38.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\moham\\desktop\\third year project\\mp_env\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\moham\\desktop\\third year project\\mp_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mediapipe opencv-python requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a53321",
   "metadata": {},
   "source": [
    "# Pre processing training data \n",
    "- Go through all lines in training.txt\n",
    "- Get class and url location \n",
    "- If class not in 5 I want -> Continue\n",
    "- Go to url file location\n",
    "    - Try to download file \n",
    "    - If fail contrinue \n",
    "    - Store downloaded img in tmp location \n",
    "    - Perform processing on image \n",
    "    - Delete image from tmp location \n",
    "- Calculate angles once landmarks from image are proccesd\n",
    "- Store angles of landmarks in csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c919141a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 2, 2: 1}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {1:2}\n",
    "a |= {2:1} \n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b5724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib \n",
    "import requests\n",
    "import csv\n",
    "from PIL import Image \n",
    "from PIL import ImageFile\n",
    "\n",
    "import time\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "min_detection_confidence = 0.5\n",
    "min_tracking_confidence = 0.5\n",
    "\n",
    "# All landmark except for hand and face specific\n",
    "RelevantLandmarks = list(mp_pose.PoseLandmark)[11:17] + list(mp_pose.PoseLandmark)[23:29]\n",
    "\n",
    "path = 'C:\\\\Users\\\\moham\\\\Desktop\\\\Third Year Project\\\\yoga82code\\\\Yoga-82\\\\'\n",
    "img_links_path = os.path.join(path, 'yoga_dataset_links')\n",
    "train_file = os.path.join(path, 'yoga_train.txt')\n",
    "test_file = os.path.join(path, 'yoga_test.txt')\n",
    "\n",
    "\n",
    "class_map = {\n",
    "    (0,2,75) : \"Warrior\", #Warrior\n",
    "    (0,0,68) : \"Tree\", #Tree \n",
    "    (4,14,68): \"Cobra\", #Cobra\n",
    "    (4,16,44): \"Plank\", #Plank \n",
    "    (0,1,17): \"DownDog\" #Downward Dog\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97165983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_link_map(train=True):\n",
    "    train_links = dict()\n",
    "    with open(train_file if train else test_file, 'r') as file:\n",
    "        for line in file:\n",
    "            img_path, l1, l2, l3 = line.split(',')\n",
    "\n",
    "            #Ending early if img not classified as what we want \n",
    "            img_class = (int(l1), int(l2), int(l3))\n",
    "\n",
    "            if img_class not in class_map:\n",
    "                continue \n",
    "\n",
    "            img_path, img_num = img_path.replace('/', ' ').split(' ') \n",
    "            img_path = img_path + '.txt'\n",
    "            \n",
    "            img_to_find = img_path.replace('.txt', '/'+img_num)\n",
    "            \n",
    "            #Add more links to dictionary \n",
    "            train_links |= {inner_line.split('\\t')[0] : inner_line.split('\\t')[1].strip() \n",
    "                            for inner_line in open(os.path.join(img_links_path, img_path))}\n",
    "    return train_links \n",
    "training_img_map = generate_link_map(train=True)\n",
    "testing_img_map = generate_link_map(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4716e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PoseLandmark.LEFT_SHOULDER: 11>,\n",
       " <PoseLandmark.RIGHT_SHOULDER: 12>,\n",
       " <PoseLandmark.LEFT_ELBOW: 13>,\n",
       " <PoseLandmark.RIGHT_ELBOW: 14>,\n",
       " <PoseLandmark.LEFT_WRIST: 15>,\n",
       " <PoseLandmark.RIGHT_WRIST: 16>,\n",
       " <PoseLandmark.LEFT_HIP: 23>,\n",
       " <PoseLandmark.RIGHT_HIP: 24>,\n",
       " <PoseLandmark.LEFT_KNEE: 25>,\n",
       " <PoseLandmark.RIGHT_KNEE: 26>,\n",
       " <PoseLandmark.LEFT_ANKLE: 27>,\n",
       " <PoseLandmark.RIGHT_ANKLE: 28>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_hip_landmark_angle_idx = (11,23,25)\n",
    "r_hip_landmark_angle_idx = (12,24,26)\n",
    "\n",
    "l_shoulder_landmark_angle_idx = (13,11,23)\n",
    "r_shoulder_landmark_angle_idx = (14,12,24)\n",
    "\n",
    "l_arm_landmark_angle_idx = (15,13,11)\n",
    "r_arm_landmark_angle_idx = (16,14,12)\n",
    "\n",
    "l_knee_landmark_angle_idx = (23,25,27)\n",
    "r_knee_landmark_angle_idx = (24,26,28)\n",
    "\n",
    "#Match idx of RelevantLandmarks \n",
    "angle_idxs_required = [\n",
    "    l_shoulder_landmark_angle_idx,\n",
    "    r_shoulder_landmark_angle_idx,\n",
    "    \n",
    "    l_arm_landmark_angle_idx,\n",
    "    r_arm_landmark_angle_idx,\n",
    "    \n",
    "    l_hip_landmark_angle_idx,\n",
    "    r_hip_landmark_angle_idx,\n",
    "    \n",
    "    l_knee_landmark_angle_idx,\n",
    "    r_knee_landmark_angle_idx\n",
    "]\n",
    "skip_landmark = {\n",
    "    mp_pose.PoseLandmark.RIGHT_ANKLE,\n",
    "    mp_pose.PoseLandmark.LEFT_ANKLE,\n",
    "    mp_pose.PoseLandmark.RIGHT_WRIST,\n",
    "    mp_pose.PoseLandmark.LEFT_WRIST\n",
    "}\n",
    "RelevantLandmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32da745a",
   "metadata": {},
   "source": [
    "# The following angles I need to classify a given yoga pose are\n",
    "- Hips\n",
    "- Shoulders\n",
    "- Arms\n",
    "- Knee\n",
    "## Repeating following for left and right \n",
    "\n",
    "### Hips\n",
    "    - Shoulder (L-11, R-12)\n",
    "    - Hip (L-23, R-24)\n",
    "    - Knee (L-25, R-26)\n",
    "### Shoulder\n",
    "    - Elbow (L-13, R-14)\n",
    "    - Shoulder (L-11, R-12)\n",
    "    - Hip (L-23, R-24)\n",
    "### Arm / Elbow \n",
    "    - Wrist (L-15, R-16)\n",
    "    - Elbow (L-13, R-14)\n",
    "    - Shoulder (L-11, R-12)\n",
    "### Knee\n",
    "    - Hip (L-23, R-24)\n",
    "    - Knee (L-25, R-26)\n",
    "    - Foot (L-27, R-28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bd5b3c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully download and read image from URL\n",
      "Could not extract pose from image: https://thumb7.shutterstock.com/display_pic_with_logo/2907205/267890807/stock-photo-yoga-pose-adho-mukha-svanasana-downward-facing-dog-poseon-watercolor-style-background-267890807.jpg Trying next image...\n",
      "\n",
      "Succesfully download and read image from URL\n",
      "Succesfully generated pose landmarks from url image https://thumb1.shutterstock.com/display_pic_with_logo/824464/225836590/stock-photo-sun-salutation-yoga-poses-in-front-of-white-background-225836590.jpg\n",
      "!!! Successfully added example row to CSV !!!\n",
      "!!! Successfully saved annotated image tmp folder !!!\n",
      "\n",
      "Succesfully download and read image from URL\n",
      "Could not extract pose from image: http://i.ytimg.com/vi/stv0C6qT-Vc/hqdefault.jpg Trying next image...\n",
      "\n",
      "Succesfully download and read image from URL\n",
      "Succesfully generated pose landmarks from url image https://naturewise.me/yoga/wp-content/gallery/dog-poses/p5230101.jpg\n",
      "!!! Successfully added example row to CSV !!!\n",
      "!!! Successfully saved annotated image tmp folder !!!\n",
      "\n",
      "COULDN'T CONVERT IMAGE TO CV2 ARRAY.. Trying next img\n",
      "\n",
      "Succesfully download and read image from URL\n",
      "Succesfully generated pose landmarks from url image https://thumb7.shutterstock.com/display_pic_with_logo/177585184/661022539/stock-photo-downward-facing-dog-pose-white-background-adho-mukha-svanasana-661022539.jpg\n",
      "!!! Successfully added example row to CSV !!!\n",
      "!!! Successfully saved annotated image tmp folder !!!\n",
      "\n",
      "Succesfully download and read image from URL\n",
      "Succesfully generated pose landmarks from url image http://blog.saracrave.com.au/wp-content/uploads/2016/09/beginner-yoga-poses-Adho-Mukha-Svanasana.jpg\n",
      "!!! Successfully added example row to CSV !!!\n",
      "!!! Successfully saved annotated image tmp folder !!!\n",
      "\n",
      "COULDN'T CONVERT IMAGE TO CV2 ARRAY.. Trying next img\n",
      "\n",
      "Succesfully download and read image from URL\n",
      "Succesfully generated pose landmarks from url image http://www.melissawest.com/wp-content/uploads/2014/04/Downward-Facing-Dog-or-Adho-Mukha-Svanasana.jpg\n",
      "!!! Successfully added example row to CSV !!!\n",
      "!!! Successfully saved annotated image tmp folder !!!\n",
      "\n",
      "Succesfully download and read image from URL\n",
      "Succesfully generated pose landmarks from url image http://thumb7.shutterstock.com/display_pic_with_logo/92519/282493265/stock-photo-yoga-series-young-woman-in-downward-facing-dog-pose-adho-mukha-svanasana-isolated-on-white-282493265.jpg\n",
      "!!! Successfully added example row to CSV !!!\n",
      "!!! Successfully saved annotated image tmp folder !!!\n",
      "\n",
      "Succesfully download and read image from URL\n",
      "Succesfully generated pose landmarks from url image https://www.melissawest.com/wp-content/uploads/2016/03/Downward-Facing-Dog-or-Adho-Mukha-Svanasana-150x150.jpg\n",
      "!!! Successfully added example row to CSV !!!\n",
      "!!! Successfully saved annotated image tmp folder !!!\n",
      "\n",
      "COULDN'T CONVERT IMAGE TO CV2 ARRAY.. Trying next img\n",
      "\n",
      "COULDN'T CONVERT IMAGE TO CV2 ARRAY.. Trying next img\n",
      "\n",
      "COULDN'T CONVERT IMAGE TO CV2 ARRAY.. Trying next img\n",
      "\n",
      "COULDN'T CONVERT IMAGE TO CV2 ARRAY.. Trying next img\n",
      "\n",
      "COULDN'T CONVERT IMAGE TO CV2 ARRAY.. Trying next img\n",
      "\n",
      "COULDN'T CONVERT IMAGE TO CV2 ARRAY.. Trying next img\n",
      "\n",
      "Succesfully download and read image from URL\n",
      "Succesfully generated pose landmarks from url image https://www.melissawest.com/wp-content/uploads/2016/06/Downward-Facing-Dog-or-Adho-Mukha-Svanasana.jpg\n",
      "!!! Successfully added example row to CSV !!!\n",
      "!!! Successfully saved annotated image tmp folder !!!\n",
      "\n",
      "Succesfully download and read image from URL\n",
      "Succesfully generated pose landmarks from url image http://c1.staticflickr.com/3/2549/3949269761_ce457f4229.jpg\n",
      "!!! Successfully added example row to CSV !!!\n",
      "!!! Successfully saved annotated image tmp folder !!!\n",
      "\n",
      "Succesfully download and read image from URL\n",
      "Succesfully generated pose landmarks from url image http://cosmomuse.com/wp-content/uploads/2015/08/Leo_Sheep_Yoga-13-e1440001478529.jpg\n",
      "!!! Successfully added example row to CSV !!!\n",
      "!!! Successfully saved annotated image tmp folder !!!\n",
      "\n",
      "Succesfully download and read image from URL\n",
      "Succesfully generated pose landmarks from url image https://i.pinimg.com/736x/c5/ae/66/c5ae660cbf6a1a4cfedc8d7756ed024e.jpg\n",
      "!!! Successfully added example row to CSV !!!\n",
      "!!! Successfully saved annotated image tmp folder !!!\n",
      "\n",
      "Succesfully download and read image from URL\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [63], line 115\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not extract pose from image: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Trying next image...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 115\u001b[0m \u001b[43mgenerate_csv_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!!! DONE !!!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn [63], line 56\u001b[0m, in \u001b[0;36mgenerate_csv_train\u001b[1;34m(train)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Initialize fresh pose tracker and run it.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp_pose\u001b[38;5;241m.\u001b[39mPose(min_detection_confidence\u001b[38;5;241m=\u001b[39mmin_detection_confidence, min_tracking_confidence\u001b[38;5;241m=\u001b[39mmin_tracking_confidence) \u001b[38;5;28;01mas\u001b[39;00m pose_tracker:\n\u001b[1;32m---> 56\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpose_tracker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     pose_landmarks \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mpose_landmarks\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m#If a one of the valid pose' was detected, write this  \u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\Third Year Project\\mp_env\\lib\\site-packages\\mediapipe\\python\\solutions\\pose.py:185\u001b[0m, in \u001b[0;36mPose.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    165\u001b[0m   \u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the pose landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\Third Year Project\\mp_env\\lib\\site-packages\\mediapipe\\python\\solution_base.py:366\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    360\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    362\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    363\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    364\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 366\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    369\u001b[0m solution_outputs \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mnamedtuple(\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSolutionOutputs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def generate_csv_train(train=True):\n",
    "    with open(train_file if train else test_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    img_map = training_img_map if train else testing_img_map \n",
    "    img_count = 0\n",
    "    with open(os.path.join(path, \"training.csv\" if train else \"testing.csv\"), 'w') as csv_out_file:\n",
    "        csv_out_writer = csv.writer(csv_out_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "        for line in lines:\n",
    "            img_found_flag = False \n",
    "            \n",
    "            img_path, l1, l2, l3 = line.split(',')\n",
    "            \n",
    "            #Ending early if img not classified as what we want \n",
    "            img_class = (int(l1), int(l2), int(l3))\n",
    "            \n",
    "            if img_class not in class_map:\n",
    "                continue\n",
    "            \n",
    "            # Ending early if for some reason I havn't included this image \n",
    "            # In our previous search \n",
    "            if img_path not in img_map:\n",
    "                print(\"IMAGE NOT IN MAP.. ERROR?\")\n",
    "                return \n",
    "                \n",
    "            img_url = img_map[img_path] \n",
    "            tmp_img = os.path.join(path,\"tmp.jpg\")\n",
    "            \n",
    "            try:\n",
    "                img_data = requests.get(img_url).content\n",
    "            except Exception as e:\n",
    "                print(f'Error in downloading image... {img_url} | Trying next image...\\n')\n",
    "                print(e)\n",
    "                continue \n",
    "            \n",
    "            with open(tmp_img, 'wb') as handler:\n",
    "                handler.write(img_data)\n",
    "            \n",
    "            try:\n",
    "                image = cv2.imread(tmp_img)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                os.remove(tmp_img)\n",
    "            except Exception as e:\n",
    "                print(\"COULDN'T CONVERT IMAGE TO CV2 ARRAY.. Trying next img\\n\")\n",
    "                continue\n",
    "            except FileNodeFoundError as e:\n",
    "                print(\"Couldn't find temp file.. Trying next img\\n\")\n",
    "                continue \n",
    "            \n",
    "            \n",
    "            print(f\"Succesfully download and read image from URL\")       \n",
    "\n",
    "            # Initialize fresh pose tracker and run it.\n",
    "            with mp_pose.Pose(min_detection_confidence=min_detection_confidence, min_tracking_confidence=min_tracking_confidence) as pose_tracker:\n",
    "                result = pose_tracker.process(image=image)\n",
    "                pose_landmarks = result.pose_landmarks\n",
    "                \n",
    "\n",
    "\n",
    "            #If a one of the valid pose' was detected, write this  \n",
    "            output_image = image.copy()\n",
    "\n",
    "            if pose_landmarks is not None:\n",
    "                print(f\"Succesfully generated pose landmarks from url image {img_url}\")\n",
    "                \n",
    "                pose_relevant_landmark_angles = []\n",
    "                # Going through all relevant landmarks, extracting their key angles\n",
    "                # Calculating the angle then adding to array \n",
    "                for i1, i2, i3 in angle_idxs_required:\n",
    "                    \n",
    "                    fst = (pose_landmarks.landmark[i1].x, pose_landmarks.landmark[i1].y)\n",
    "                    snd = (pose_landmarks.landmark[i2].x, pose_landmarks.landmark[i2].y)\n",
    "                    thrd = (pose_landmarks.landmark[i3].x, pose_landmarks.landmark[i3].y)\n",
    "                    \n",
    "                    \n",
    "                    pose_relevant_landmark_angles.append(calc_angle(fst, snd, thrd))\n",
    "\n",
    "                \n",
    "                \n",
    "                #Getting cords of the landmarks FOR ANGLES WE CALC'D CORDS FOR\n",
    "                pose_relevant_landmark_cords = [[pose_landmarks.landmark[idx].x, pose_landmarks.landmark[idx].y]\n",
    "                                               for _, idx, _ in angle_idxs_required if idx not in skip_landmark]\n",
    "                \n",
    "                \n",
    "                    \n",
    "               \n",
    "                \n",
    "\n",
    "                # Write pose sample to CSV.\n",
    "                pose_relevant_landmark_angles_data = np.around(pose_relevant_landmark_angles, 5).astype(str).tolist()\n",
    "                pose_relevant_landmark_angles_visual = np.around(pose_relevant_landmark_angles, 2).astype(str).tolist()\n",
    "                \n",
    "                csv_out_writer.writerow([class_map[img_class]] + pose_relevant_landmark_angles_data)\n",
    "                print(\"!!! Successfully added example row to CSV !!!\")\n",
    "                \n",
    "                 # Map pose landmarks from [0, 1] range to absolute coordinates to get\n",
    "                # correct aspect ratio.\n",
    "                frame_height, frame_width = output_image.shape[:2]\n",
    "                pose_relevant_landmark_cords *= np.array([frame_width, frame_height])\n",
    "                real_cords = tuple(pose_relevant_landmark_cords.astype(int))\n",
    "                \n",
    "                \n",
    "                for idx, kp_cords in enumerate(real_cords):\n",
    "                    cv2.putText(output_image, f'{pose_relevant_landmark_angles_visual[idx]}', kp_cords, \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA) \n",
    "                \n",
    "                #Save image and recolour\n",
    "                cv2.imwrite(os.path.join(path, 'tmp/tmp_img_' + str(img_count) + '.png'), cv2.cvtColor(output_image, cv2.COLOR_RGB2BGR))\n",
    "                img_count+=1\n",
    "                print(\"!!! Successfully saved annotated image tmp folder !!!\\n\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"Could not extract pose from image: {img_url} Trying next image...\\n\")\n",
    "generate_csv_train()\n",
    "print(\"!!! DONE !!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83ca95c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)    \n",
    "    c = np.array(c)   \n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 380-angle \n",
    "    \n",
    "    return angle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307d67b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('mp_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "c03d7ca79527c43668de5fef191e6a32e993596d47f3147d82e5050d734e1650"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
